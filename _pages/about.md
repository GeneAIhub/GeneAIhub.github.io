---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I'm a Ph.D. candidate in School of Electrical Engineering and Automation at Hefei University of Technology, and I'm now a visiting student in Faculty of Health Data Science at Juntendo University. I have published 5+ papers with 
 <a href='https://scholar.google.com/citations?user=WMkMTb4AAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>.

My research interest includes: 
- Physiological signal analysis
- Human-exoskeleton interaction
- Brain function connectivity analysis


# üéì Educations 
- *2019.09 - 2024.06*, Ph.D. in School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, China. <a href="https://en.hfut.edu.cn/"><img class="svg" src="/images/hfut.png" width="16pt"></a> 
- *2023.04 - 2024.04*, Ph.D. in Graduate School of Medicine, Juntendo University, Tokyo, Japan. (Visiting Student) <a href="https://en.juntendo.ac.jp/"><img class="svg" src="/images/juntendo.png" width="16pt"></a> 
- *2016.09 - 2019.06*, M.Sc. in School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, China. <a href="https://en.hfut.edu.cn/"><img class="svg" src="/images/hfut.png" width="16pt"></a> 
- *2012.09 - 2016.06*, B.Sc. in School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, China. <a href="https://en.hfut.edu.cn/"><img class="svg" src="/images/hfut.png" width="16pt"></a> 


# üìù Publications 
<h3 align="center">2023</h3>
<div style="border-bottom: 1px solid #000; margin: 0px 0;"></div>

<div class='paper-box'>
    <div class='paper-box-image' style="text-align:center;">
        <img src='images/tnnls23.jpg' alt="sym" style="width:300px;height:200px;margin:auto;vertical-align:middle">
    </div>
    <div class='paper-box-text'>
        <a href="https://ieeexplore.ieee.org/document/9609089">
            <papertitle> A Novel Approach to Detecting Muscle Fatigue Based on sEMG by Using Neural Architecture Search Framework </papertitle>
        </a>
        <br>
        <strong>Shurun Wang</strong>, Hao Tang*, Bin Wang, et al.
        <br>
        <em> IEEE Transactions on Neural Networks ÔºÜ Learning Systems</em>, 2023 <a href="https://github.com/Shurun-Wang/NAS">[code]</a>
        <p></p>
        <p>We propose a hierarchical exploration mechanism based on reinforcement learning to automatically generate high-performance CNN models, which can be used in detecting the muscle fatigue.</p>
    </div>
</div>


<h3 align="center">2022</h3>
<div style="border-bottom: 1px solid #000; margin: 0px 0;"></div>

<div class='paper-box'>
    <div class='paper-box-image' style="text-align:center;">
        <img src='images/sensors2022.svg' alt="sym" style="width:300px;height:200px;margin:auto;vertical-align:middle">
    </div>
    <div class='paper-box-text'>
        <a href="https://recognize-anything.github.io/">
            <papertitle> Recognize Anything: A Strong Image Tagging Model </papertitle>
        </a>
        <br>
        Youcai Zhang*, <strong>Xinyu Huang*</strong>, Jinyu Ma*, Zhaoyang Li*, Zhaochuan Luo, Yanchun Xie, Yuzhuo Qin, Tong Luo, Yaqian Li, Shilong Liu, Yandong Guo, Lei Zhang
        <br>
        <em>Tech report</em>, 2023
        <br>
        <a href="https://recognize-anything.github.io/">project page</a> /
        <a href="https://arxiv.org/abs/2306.03514">arXiv</a> /
        <a href="https://huggingface.co/spaces/xinyu1205/Tag2Text">demo</a> /
        <a href="https://github.com/xinyu1205/Recognize_Anything-Tag2Text">code</a>
        <p></p>
        <p><strong>Recognition and localization are two foundation computer vision tasks.</strong> <strong>The Segment Anything Model (SAM)</strong> excels in <strong>localization capabilities</strong>, while it falls short when it comes to <strong>recognition tasks</strong>. <strong>The Recognize Anything Model (RAM)</strong> exhibits <strong>exceptional recognition abilities</strong>, in terms of <strong>both accuracy and scope</strong>.</p>
    </div>
</div>


# üèÖ Honors and Awards
- *2023.04* Sponsored by the China Scholarship Council
- *2022.10* National scholarship for doctoral students


# üí¨ News
- *2023.09*, Qi Liu and I have entered into matrimony.



  
